«Эволюционные алгоритмы»
Определение: представляет собой подмножество эволюционных вычислений, общий алгоритм метаэвристической оптимизации на основе популяции, который использует механизмы, вдохновлённые биологической эволюцией: размножение, мутация, рекомбинация и отбор (эволюционная стратегия), возможные решения играют в задаче оптимизации роль особей в популяции, а функция приспособленности определяет качество решений. Затем происходит эволюция популяции после многократного применения вышеуказанных операторов.
Эволюционные вычисления  в компьютерных науках представляют собой  семейство алгоритмов глобальной оптимизации, вдохновлённых биологической эволюцией,  являющиеся областью искусственного интеллекта и мягких вычислений (алгоритмы, которые терпимы к неточности, неопределённости, частичной правдивости и приближению:  нейронные сети, нечеткая логика и эволюционные вычисления). В техническом плане они представляют собой семейство основанных на популяциях алгоритмов решения проблем методом проб и ошибок с метаэвристическим (стратегия, но неточная) или стохастическим (случайным) характером оптимизации. 
Эволюционная стратегия модель, которая использует естественные представления, зависящие от проблемы, и в первую очередь мутацию и отбор, в качестве операторов поиска, операторы применяются в цикле. Итерация цикла называется поколением. Последовательность поколений продолжается до тех пор, пока не будет выполнен критерий завершения. Для пространств поиска с действительными значениями мутация выполняется путём добавления нормально распределенного случайного вектора.
Имеет следующую последовательность:

Компоненты:
1.Начальная популяция (генерируется автоматически или подбирается на основе определённых признаков).
2.Операторы скрещивания:
a)Операторы на основе разрезов:
-одноточечный разрез, который ставится в случайном месте одинаково для обеих хромосом, после чего на его основе делается перестановка элементов;

-многоточечный разрез, аналогичен одноточечному с поправкой на то, разрезов больше одного.
b)Операторы на основе вероятности:
-равномерный кроссовер, в котором у дочерней хромосомы поочерёдно определяется вероятность выбора гена от каждого из родителей, что даёт равный шанс перехода генов каждого из родителей;
-дискретная и промежуточная рекомбинации, которые позволяют выбрать гены дочерней хромосомы путём разложения хромосомы размером n в n-мерное пространство для случайного выбора вершин, в первом случае выбираются только состояния в вершинах многогранника, во втором  ещё и промежуточные состояния (актуально для действительных чисел).

3.Операторы мутации:
a)операторы обмена (перестановка элементов внутри хромосомы):
-простой обмен (перестановка двух случайных генов);
-скрэмблер (перестановка элементов в определённой области случайным образом);
-инверсная (зеркальный переворот всех элементов в хромосоме);
b)операторы сброса значения:
-битовые переворот (переворот 0 на 1 и 1 на 0);
-случайный сброс (выбирается случайное число из допустимого диапазона).
c)мутация на основе законов распределения:
-мутация на основе закона распределения (без учёта ограничений) случайного величины относительно диапазона значений или их величины;
-мутация с учётом ограничений, в которой в наименьшие изменения наиболее вероятны.
4.Операторы отбора:
a)выбор колеса рулетки (на основе фитнеса и равномерный);
b)выбор на основе турнира;
c)элитарный отбор;
d)отбор на основе градиента (отбор Больцмана).
5.Фитнес-функция (функция пригодности, особый тип целевой функции, который используется для обобщения в виде единого показателя качества того, насколько близко данное проектное решение к достижению поставленных целей). Целевая функция  вещественная или целочисленная функция нескольких переменных, подлежащая оптимизации в целях решения некоторой оптимизационной задачи, может быть как в виде функции потерь (которую надо минимизировать), так ей обратных (которые надо максимизировать):  функция вознаграждения, функция прибыли, функция полезности, функция пригодности.
Особенности:
Ограниченная структура решений (в задачах программирования означает, что программа имеет либо ограничения по памяти, либо по времени, либо по структуре кода), в более простом варианте обозначает то, что ограничены размеры популяции.
Основным оператором является оператор мутации для повышения разнообразия представителей популяции (может применятся несколько), как правило, работает с действительными значениями в широком диапазоне.
Основные задачи: аппроксимация, симуляция и оптимизация.
«Генетические алгоритмы»
Определение: конкретизированный вид эволюционных алгоритмов, который обычно используется для создания высококачественных решений задач оптимизации и поиска, полагаясь на биологически вдохновлённые операторы.
Особенности в отличиях:
Неограниченная структура решений.
Основным оператором является оператор скрещивания для регуляризации пространства поиска решений.
Основные задачи: поиск решений и оптимизация.
«Многослойные нейронные сети»
Компоненты:
1.Архитектура нейрона:
a)количество входов;
b)количество весов;
c)функция активации;
d)количество выходов.
2.Архитектура нейронной сети:
a)количество слоёв нейронной сети;
b)количество связей между нейронами в сети (полносвязная и неполносвязная);
c)количество нейронов в слое и их функции активации.
3.Оптимизатор нейронной сети (алгоритмы, которые используются для оптимизации параметров нейронной сети, таких как веса и смещения, с целью уменьшения степени ошибки модели и улучшения её качества):
a)метод градиентного спуска, который заключается в изменении параметров нейронной сети в направлении, противоположном градиенту функции потерь, градиент функции потерь определяет направление, в котором следует изменять параметры модели, чтобы уменьшить ошибку.
b)метод обратного распространения ошибки, который заключается в следующих шагах:
1)прямое распространение сигнала через нейронную сеть, начиная с входного слоя и заканчивая выходным слоем, каждый нейрон вычисляет свой выход на основе входных данных и активационной функции.
2)вычисляется ошибка на выходном слое с помощью функции потерь, которая сравнивает выходные значения сети и желаемые значения, определённые в обучающих данных.
3)ошибка распространяется обратно через сеть, начиная с выходного слоя и двигаясь к входному слою, каждый нейрон получает градиент ошибки от вышестоящего нейрона и обновляет свои веса с помощью градиентного спуска.
4)шаги 1-3 повторяются для каждого обучающего примера в наборе данных, этот процесс называется эпохой обучения.
5)после завершения всех эпох обучения, модель может быть использована для предсказания выходных значений на новых данных.
4.Функция потерь и метрики качества.
a)Функции потерь позволяют понять, насколько ожидаемые результаты отличаются от полученных:
-Простая ошибка как разница между ожиданием и результатом:
loss = y - f(x),
где y - ожидаемый результат
x - полученный результат;
-Функция ошибки классификации, которая возвращает 0, если предсказание модели верно и 1, если неверно:
CLF = 1 - (accuracy / 100)
где:
accuracy - процент верных предсказаний модели;
-Среднеквадратичная ошибка (Mean Squared Error, MSE)  это наиболее распространенная функция потерь для задач регрессии, она определяется как средняя арифметическая квадратичных разностей между предсказанными и истинными значениями,
MSE = 1/n * sum((y - ŷ)^2)
где:
n - количество наблюдений или размер выборки
y - истинное значение целевой переменной
ŷ - предсказанное моделью значение целевой переменной
MSE вычисляет среднее арифметическое квадратов отклонений прогнозов модели от истинных значений. В результате, чем меньше значение MSE, тем лучше модель предсказывает значения целевой переменной;
-Кросс-энтропия (Cross-Entropy Loss)  это функция потерь, которая используется для задач классификации, она определяется как отрицательная взвешенная сумма логарифмов предсказанных вероятностей классов,
формула Кросс-энтропии (Cross-Entropy Loss) для бинарной классификации выглядит следующим образом:
CE = - (1/N) * sum(y * log(ŷ) + (1 - y) * log(1 - ŷ))
где:
N - количество наблюдений или размер выборки
y - истинное значение класса (0 или 1)
ŷ - предсказанная моделью вероятность класса 1
b)Метрика качества позволяет определить, насколько хорошо модель обучена на заданной выборке данных:
-Accuracy (точность)  это доля правильных ответов, которые модель даёт на тестовой выборке данных.
-Precision (точность) это доля правильных предсказаний положительного класса (true positives/(true positives + false positives)).
-Recall (полнота) это доля правильно предсказанных положительных значений относительно всех реальных положительных значений (true positives/(true positives + false negatives)).
5.Регулязатортехника, которая помогает предотвратить переобучение модели на тренировочных данных, она включает в себя добавление дополнительных условий на параметры модели во время обучения, чтобы предотвратить экстремальные значения весов и смещений, которые могут привести к переобучению.
a)L1 регуляризация добавляет штраф относительно суммы абсолютных значений весов нейронной сети (L1 loss = λ * Σ |w|, где w - весовые коэффициенты модели, λ - коэффициент регуляризации.).
b)L2 регуляризация добавляет штраф относительно суммы квадратов весов нейронной сети (L2 loss = λ * Σ w^2, где w - весовые коэффициенты модели, λ - коэффициент регуляризации).
c)Dropout случайным образом отключает некоторые нейроны в каждом слое во время обучения сети, чтобы предотвратить переобучение.
Функции активации позволяют нейронам в сети передавать информацию и выполнять необходимые преобразования входных данных:
Ступенчатая функция активации (step function)  это простая нелинейная функция, которая имеет значение 1, если её аргумент больше или равен 0, и 0 в противном случае. Формально, ступенчатую функцию активации можно определить следующим образом:
f(x) = 1, x >= 0
f(x) = 0, x < 0
Также существует вариант ступенчатой функции активации, которая имеет значение 1 при x строго больше 0:
f(x) = 1, x > 0
f(x) = 0, x <= 0
Ступенчатая функция активации может использоваться в некоторых типах нейронных сетей, например, в однослойных персептронах, ступенчатая функция активации нечасто применяется из-за того, что она не учитывает относительную силу входных сигналов, которые приходят на нейрон, также она дискретна и недифференцируема, её более популярными аналогами являются сигмоидальная функция или ReLU.
Сигмоидная функция (sigmoid)  функция, которая возвращает значения между 0 и 1. Она имеет S-образную форму, что позволяет ей выполнять бинарную классификацию входных данных, её главный недостаток - тенденция к насыщению (то есть, когда функция принимает значения близкие к 0 или 1, её градиент сильно затухает).
Гиперболический тангенс (tanh)  эта функция также имеет S-образную форму, но возвращает значения в диапазоне от -1 до 1. В отличие от сигмоидной функции, гиперболический тангенс обладает нулевым центром (среднее значение равно 0), что делает его полезным для центрирования данных.
ReLU (Rectified Linear Unit)  Эта функция возвращает значение равное 0, если вход меньше или равен 0, и значение входа, если он больше нуля. Функция ReLU очень популярна в нейронных сетях, потому что она проста, быстра и обычно работает лучше других функций активации на практике. Она также помогает бороться с проблемой затухания градиентов.
Leaky ReLU (LReLU)эта функция похожа на выполнение ReLU за исключением того, что она имеет небольшой наклон для отрицательных значений. Это помогает избежать изменения знака градиента, что может улучшить скорость сходимости.
Softmax  Эта функция используется обычно в последнем слое нейронной сети, чтобы перевести выходные значения в вероятностное распределение. Она принимает на вход вектор значений и возвращает вероятности находящиеся в интервале [0, 1], сумма которых равна 1. Softmax позволяет выбирать из нескольких классов, исходя из наиболее вероятного класса.
Maxout  Эта функция возвращает максимальное значение из нескольких линейных функций. Она может быть использована для отображения более сложных функций, чем простые линейные модели.
Особенности:
Многослойность:
В нейронной сети много слоёв используются для решения более сложных задач, которые требуют высокой степени абстракции и обобщения.
Каждый слой в сети отвечает за определённый аспект обработки данных. Некоторые слои могут обрабатывать простые характеристики, такие как грани и контуры, в то время как другие могут анализировать более сложные взаимосвязи между наборами характеристик.
Применение многих слоёв позволяет моделировать более сложные функции, которые не могут быть представлены более простыми моделями. Это может помочь в обработке различных типов данных, таких как текст, изображения, аудио и видео.
Количество нейронов в слое:
Увеличение количества нейронов в слоях нейронной сети позволяет улучшить её способность к обработке информации и улучшить точность предсказания.
При добавлении нейронов в слои, нейронная сеть имеет больше данных, которые могут быть использованы для обучения, что позволяет лучше извлекать закономерности и паттерны в данных.
Больше нейронов также позволяют моделировать более сложные и абстрактные зависимости между переменными, что помогает в обработке более сложных типов данных.
Однако, увеличение количества нейронов может также привести к переобучению.
Выбор функции активации:
Однако, выбор функции активации зависит от конкретной задачи и оптимального результата, а также от архитектуры нейронной сети. Некоторые функции могут быть более подходящими для определённых типов данных или задач, например, функция sigmoid лучше подходит для бинарной классификации.
Кроме того, в некоторых случаях могут быть использованы нестандартные функции активации, разработанные специально для решения определённых задач. Например, любые непрерывные, монотонно возрастающие и дифференцируемые функции могут быть использованы в качестве функции активации. Таким образом, выбор оптимальной функции активации играет важную роль в достижении результатов.
«Многоагентные системы»
СМОТРЕТЬ ФАЙЛ С ЗАДАНИЕМ К ПРАКТИЧЕСКОЙ РАБОТЕ №1!
Содержание файла к практической работе №1:
Практическая работа № 1
«Многоагентные системы»
по дисциплине «Разработка систем поддержки принятия решений»
Цели: приобрести навыки реализации многоагентных систем.
Задачи:
1)создать программную реализацию системы, основанной на технологии интеллектуальных агентов, которая должна решать определённую задачу вроде симуляции, оптимизации или распределённой работы (как это реализовано в сетях передачи данных, архитектуре микросервисов или робототехнике), программа должна иметь следующий минимальный стек:
– создать не менее двух агентов, способных взаимодействовать друг с другом (причём один из агентов может выступать самой средой, в которой находится или с которой взаимодействует второй агент);
– использовать существующие языки программирования (вроде SARL, Jade, Jason, ZEUS, IDOL и т.д.), фреймворки (вроде MARL, PADE, Met4FoF, NARVAL, JIAC и т.д.) или платформы (вроде JaCaMo, A-Globe, ADK, DESIRE, SPARK и т.д.) для создания многоагентных систем, используемый инструмент необходимо описать в соответствии с тем, какие его элементы были использованы в программе (то есть, например, если были использованы 50 лексем, то их всех нужно описать в отчёте в теоретическое части);
– реализовать следующие свойства агентов:
a)обучаемость (способность самостоятельного решения однотипных задач без использования базы знаний и/или способность компенсировать неточные или недостоверные данные от других агентов или базы знаний);
b)автономность (способность решать задачу даже в нетривиальных условиях без вмешательства человека);
c)реактивность (оперативная реакция на изменение среды);
d)про-активность (целеполагание и поиск оптимального решения)
e)социальность (взаимодействие с другими агентами для достижения собственных и общих целей, главным образом, посредством передачи сообщений с запросом и предоставлении информации)
2)в качестве дополнительных элементов многоагентной системы (на доп. баллы, наиболее важные пункты подчёркнуты) необходимо:
– реализовать язык описания свойств агентов (то есть реализовать KIF, а ещё лучше реализовать постепенно вытесняющий его SUO-KIF, можно и создать свой, однако его необходимо полностью описать, то есть сделать руководство пользователя по языку), а также язык запросов и манипулирования знаниями (то есть реализовать KQML или постепенно его заменяющий FIPA-ACL, но он ещё слабо структурирован, можно и свой, но опять же – с полным описанием) 
– реализовать BDI-модель, обуславливающую более реалистичное поведение агентов в многоагентной среде (см. Примечание);
– реализовать агентов 3-ёх следующих видов:
a)пассивных (агенты, не имеющие целей и не следующие BDI-модели, как правило, существуют в качестве инструментов, посредников или помех для других агентов в системе);
b)активных (агенты, имеющие простые и быстро достижимые цели вроде передачи сообщений, выполнения мобильных действий и простых вычислений);
c)когнитивных (агенты, выполняющие сложные, трудоёмкие и долгие по времени вычисления и являющаяся интеллектуальным центром системы, а также основным потребителем и наполнителем базы знаний);
– реализовать следующие дополнительные свойства агентов:
a)мобильность (способность агентов перемещаться внутри среды, например, в иерархии агентов, в некоторой матрице или в n-мерном виртуальном пространстве);
b)кооперативность (способность агентов объединяться для совместного решения задачи, см. Примечание)
c)конкурентность (способность агентов противостоять друг другу для выполнения только собственных интересов, см. Примечание)
d)правдивость (агент не может специально сообщить неправдивую информацию)
e)наличие системы знаний (наличие у агентов МПЗ и собственных оперативных знаний на её основе)
f)рациональность (логическая последовательность действий в рамках своих убеждений и знаний и оптимальное взаимодействие с другими агентами);
– реализовать интеллект агентов, который должен основываться  на процедурных методах, функциональных методах, научных (система логический заключений на основе эмпирических наблюдений) методах, обучении с подкреплением, теории принятия решений и методах алгоритмов поиска (хотя бы на одном их них). 
ПРИМЕЧАНИЕ:
– BDI-модель (Beliefs, Desires, Intentions – убеждения, желания, намерения) основана на теории практичного человеческого  мышления Майкла Братмана, убеждения представляют собой информационное состояние агента (то есть знания об окружающем мире), они хранятся в базе знаний системы, в базе самого агенты или базах других агентов, желания представляют собой элементы мотивации агента, то есть некоторые детерминированные (определённые) действия для достижения конечной цели (найти наиболее короткий путь от одной точки, до другой, достичь вершины иерархии, передать важное приватное сообщение определённому агенту и т.п.), при этом цели не должны быть конфликтующими (например, создать и удалить запись одновременно), намерения представляют собой конкретные решения (план действий или уже совершённые действия) для выполнения желаний, план действий может представлять собой конкретный воспроизведённый самим агентом алгоритм (например, построенный граф состояний или дерево решений), при этом планы могут динамично изменятся в во время их выполнения (главным образом, из-за свойств активности и про-активности);
– кооперативность и конкурентность являются основными способами достижения свойства социальности агентов, если первое подразумевает передачу другим агентам нужной им достоверной (не важно, является ли она таковой на самом деле, главное, что отправитель уверен в её достоверности) информации и помощь другим агентам в достижении их целей (например, позволить воспользоваться своей функцией, которой нет у другого агента, добыть нужную для другого агента информацию или выполнить для него определённое действие), то последнее подразумевает возможность одного агента обманывать другого и всячески мешать выполнению его действий, или хотя бы и не мешать, и не помогать, а думать только о себе. 
